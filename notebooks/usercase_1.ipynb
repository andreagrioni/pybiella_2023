{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METABRIC Dataset\n",
    "\n",
    "paper [here](https://www.nature.com/articles/ncomms11479)\n",
    "\n",
    "dataset [here](https://www.kaggle.com/datasets/raghadalharbi/breast-cancer-gene-expression-profiles-metabric)\n",
    "\n",
    "\n",
    "Project Description:\n",
    "\n",
    "This notebook summarizes the key scientific inquiries used in the context of a pharmaceutical company for analyzing clinical trials. Its purpose is to offer a comprehensive look into the data analysis processes within a pharmaceutical company, with a specific emphasis on biomarker discovery. It also includes a comparison of the same analysis executed in both R and Python.\n",
    "\n",
    "Analysis agenda:\n",
    "\n",
    "This notebook will cover the following aspect:\n",
    "\n",
    "1. Exploratory Data analysis [?]\n",
    "2. Survival Analysis\n",
    "3. Differential Expression Analysis\n",
    "4. Mutation [?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook setup\n",
    "## impoort packages\n",
    "import collections\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratiry Data Analysis\n",
    "\n",
    "Here we first look at the samples and features to have an idea of what type of data we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load METABRIC dataset\n",
    "## load data\n",
    "metabric_data = pd.read_csv(\n",
    "    '../data/raw/METABRIC_RNA_Mutation.csv', # path to data\n",
    "    index_col=0, # use first column as index\n",
    "    low_memory=False # avoid warning\n",
    "    )\n",
    "## show header\n",
    "metabric_data.head()    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## separate dataset\n",
    "\n",
    "The csv file is a all in one table with different data types. The code below breaks the dataset into column subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from 0 to 30 are the clinical data\n",
    "clinical = metabric_data.iloc[:, :30].add_suffix(\"_meta\")\n",
    "print(f'clinical data shape: {clinical.shape}')\n",
    "# from 30 to 519 are the gene expression data\n",
    "expression = metabric_data.iloc[:, 30:519].add_suffix(\"_expr\")\n",
    "print(f'expression data shape: {expression.shape}')\n",
    "# from 519 to end are the mutation data\n",
    "mutation = metabric_data.iloc[:, 519:]\n",
    "print(f'mutation data shape: {mutation.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clinical Data Exploration\n",
    "\n",
    "Perform an high level exploration of the clinical features, with main focus on survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode variables in overall_survival_meta\n",
    "# to categorical variables\n",
    "mapping = { 0 : \"dead\", 1 : \"alive\" }\n",
    "# apply the mapping to the column\n",
    "clinical[\"overall_survival_meta\"] = clinical[\"overall_survival_meta\"].map(mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure and specify the number of subplots and their arrangement (2 rows, 2 columns)\n",
    "fig, ax = plt.subplots(3, 2, figsize=(15, 14))\n",
    "# Plot the distribution of age at diagnosis in the first subplot\n",
    "sns.histplot(\n",
    "    data=clinical, \n",
    "    x=\"age_at_diagnosis_meta\", \n",
    "    hue=\"overall_survival_meta\",\n",
    "    ax=ax[0, 0]\n",
    "    )\n",
    "# Plot the distribution of total mutations in the second subplot\n",
    "sns.histplot(\n",
    "    data=clinical, \n",
    "    x=\"mutation_count_meta\",\n",
    "    hue=\"overall_survival_meta\",\n",
    "    ax=ax[0, 1]\n",
    "    )\n",
    "# Plot the distribution of tumour size in the third subplot\n",
    "sns.histplot(\n",
    "    data=clinical, \n",
    "    x=\"tumor_size_meta\", \n",
    "    hue=\"overall_survival_meta\",\n",
    "    ax=ax[1, 0]\n",
    ")\n",
    "# Plot the distribution of age at diagnosis in the fourth subplot\n",
    "sns.boxplot(\n",
    "    data=clinical, \n",
    "    x=\"overall_survival_meta\", \n",
    "    y=\"age_at_diagnosis_meta\",\n",
    "    ax=ax[1, 1]\n",
    "    )\n",
    "# plot the correlation between age at diagnosis and total mutations\n",
    "sns.scatterplot(\n",
    "    data=clinical,\n",
    "    x=\"tumor_size_meta\",\n",
    "    y=\"mutation_count_meta\",\n",
    "    hue=\"overall_survival_meta\",\n",
    "    ax=ax[2, 0]\n",
    ")\n",
    "# plot che correlation between age at diagnosis and overall_survival_months_meta\n",
    "sns.scatterplot(\n",
    "    data=clinical,\n",
    "    x=\"age_at_diagnosis_meta\",\n",
    "    y=\"overall_survival_months_meta\",\n",
    "    hue=\"overall_survival_meta\",\n",
    "    ax=ax[2, 1]\n",
    ")\n",
    "# calculate the correlation between age at diagnosis and total mutations\n",
    "corr_1 = clinical[[\"tumor_size_meta\", \"mutation_count_meta\"]].corr(method=\"spearman\")\n",
    "# calculate the correlation between age at diagnosis and overall_survival_months_meta\n",
    "corr_2 = clinical[[\"age_at_diagnosis_meta\", \"overall_survival_months_meta\"]].corr(method=\"spearman\")\n",
    "# calculate p-value\n",
    "p_vals = collections.defaultdict(list)\n",
    "# Perform t-test\n",
    "for target in [\"age_at_diagnosis_meta\", \"mutation_count_meta\", \"tumor_size_meta\"]:\n",
    "    _, p_value = ttest_ind(\n",
    "        clinical[clinical[\"overall_survival_meta\"] == 'alive'][target].dropna(),\n",
    "        clinical[clinical[\"overall_survival_meta\"] == 'dead'][target].dropna(),\n",
    "    )\n",
    "    p_vals[target].append(p_value)\n",
    "# set the title of the figure\n",
    "ax[0,0].set(\n",
    "    title=f\"dist of age at diagnosis by survival | p-value: {p_vals['age_at_diagnosis_meta'][0]:.3f}\"\n",
    "    )\n",
    "ax[0,1].set(\n",
    "    title=f\"dist of age at diagnosis by survival | p-value: {p_vals['mutation_count_meta'][0]:.3f}\"\n",
    "    )\n",
    "ax[1,0].set(\n",
    "    title=f\"dist of total mutations by survival | p-value: {p_vals['tumor_size_meta'][0]:.3f}\"\n",
    "    )\n",
    "ax[1,1].set(\n",
    "    title=f\"dist of age at diagnosis by survival | p-value: {p_vals['age_at_diagnosis_meta'][0]:.3f}\"\n",
    "    )\n",
    "ax[2,0].set(\n",
    "    title=f\"corr of age at diagnosis and total mutations | corr: {corr_1.iloc[0,1]:.3f}\"\n",
    ")\n",
    "ax[2,1].set(\n",
    "    title=f\"corr of age at diagnosis and overall survival | corr: {corr_2.iloc[0,1]:.3f}\"\n",
    ")\n",
    "# show figure\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore correlation across all clinical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only numeric columns from clinical data\n",
    "corr_data = clinical.select_dtypes(include=['number'])\n",
    "# calculate the correlation matrix\n",
    "clinical_corr = corr_data.corr(method='spearman')\n",
    "# plot the correlation matrix with plotly\n",
    "import plotly.express as px\n",
    "# generate heatmap\n",
    "fig = px.imshow(\n",
    "    clinical_corr, \n",
    "    zmin=-1, \n",
    "    zmax=1\n",
    ")\n",
    "# show figure\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survival Analysis\n",
    "\n",
    "Survival analysis is a statistical method used to analyze the time until an event of interest occurs, such as death, failure, or censoring. The goal of survival analysis is to study the distribution of the time to the event and identify factors that influence the time to the event. It is commonly used in medical research to study time to death, time to failure in mechanical systems, and time to a certain outcome in clinical trials. Survival analysis takes into account the fact that not all individuals will experience the event of interest, and it uses methods such as the Kaplan-Meier estimate and Cox regression to account for censoring, which occurs when some individuals do not experience the event before the study ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'clinical data shape: {clinical.shape}')\n",
    "survival_data = clinical[clinical['death_from_cancer_meta'] != \"Died of Other Causes\"].copy()\n",
    "print(f'survival data shape: {survival_data.shape}')\n",
    "# convert the survival type to boolean\n",
    "survival_data['death_from_cancer_meta'] = survival_data['death_from_cancer_meta'].map({'Living': False, 'Died of Disease': True})\n",
    "# remove rows with na values\n",
    "survival_data.dropna(inplace=True, subset=['overall_survival_months_meta', 'death_from_cancer_meta'])\n",
    "print(f'survival data shape: {survival_data.shape}')\n",
    "# assign to data_x and data_y and convert to array-like\n",
    "death_event = survival_data['death_from_cancer_meta'].to_list()\n",
    "time_moth = survival_data['overall_survival_months_meta'].to_list()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we build a kaplan meier curve of survival with the package [scikit-survival](https://scikit-survival.readthedocs.io/en/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "\n",
    "# fit the kaplar-meier estimator\n",
    "kmf = KaplanMeierFitter()\n",
    "kmf.fit(time_moth, death_event)\n",
    "# Plot the Kaplan-Meier curve\n",
    "kmf.plot(figsize=(10,6), linewidth=2)\n",
    "plt.title(\"Kaplan-Meier Survival Curve\")\n",
    "plt.xlabel(\"Time (days)\")\n",
    "plt.ylabel(\"Survival Probability\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate survival by group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "placeholder = survival_data.dropna(subset=['cellularity_meta']).copy()\n",
    "\n",
    "event_col = 'death_from_cancer_meta'\n",
    "time_col = 'overall_survival_months_meta'\n",
    "\n",
    "group_col = 'cellularity_meta'\n",
    "groups = placeholder[group_col].unique()\n",
    "\n",
    "# Fit the Kaplan-Meier model for each group\n",
    "kmf = KaplanMeierFitter()\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "for group in groups:\n",
    "    group_data = placeholder[placeholder[group_col] == group]\n",
    "    kmf.fit(group_data[time_col], event_observed=group_data[event_col], label=group)\n",
    "    kmf.plot(ax=ax, linewidth=2)\n",
    "\n",
    "# Plot the Kaplan-Meier curve\n",
    "plt.title(\"Kaplan-Meier Survival Curve by Group\")\n",
    "plt.xlabel(\"Time (days)\")\n",
    "plt.ylabel(\"Survival Probability\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "placeholder = survival_data.dropna(subset=['cellularity_meta']).copy()\n",
    "\n",
    "event_col = 'death_from_cancer_meta'\n",
    "time_col = 'overall_survival_months_meta'\n",
    "\n",
    "group_col = 'her2_status_meta'\n",
    "groups = placeholder[group_col].unique()\n",
    "\n",
    "# Fit the Kaplan-Meier model for each group\n",
    "kmf = KaplanMeierFitter()\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "for group in groups:\n",
    "    group_data = placeholder[placeholder[group_col] == group]\n",
    "    kmf.fit(group_data[time_col], event_observed=group_data[event_col], label=group)\n",
    "    kmf.plot(ax=ax, linewidth=2)\n",
    "\n",
    "# Plot the Kaplan-Meier curve\n",
    "plt.title(\"Kaplan-Meier Survival Curve by Group\")\n",
    "plt.xlabel(\"Time (days)\")\n",
    "plt.ylabel(\"Survival Probability\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cox's Proportion Hazard's Model\n",
    "\n",
    "The Cox Proportional Hazards Model is a statistical model used to analyze the survival time of individuals or objects, taking into account the effects of one or more predictor variables. It is commonly used in medical research, engineering, and other fields. In the model, the hazard (the risk of an event occurring at a specific time) is assumed to be proportional over time for individuals with different values of the predictor variables. The model estimates the hazard ratios, which can be used to compare the risks of different groups of individuals or objects and to make predictions about future events.\n",
    "\n",
    "Hazard ratios are a measure of the relative risk of an event (such as death or failure) occurring in one group compared to another. In the Cox Proportional Hazards Model, hazard ratios represent the exponential of the coefficients estimated for the predictor variables in the model. The hazard ratio for a predictor variable tells us how much the hazard (the risk of an event occurring) increases or decreases with a unit increase in that variable, while holding all other variables constant.\n",
    "\n",
    "For example, if the hazard ratio for a predictor variable is 2, it means that, for individuals with a one-unit increase in that variable, the risk of the event occurring is two times higher than for individuals with a lower value of that variable. On the other hand, if the hazard ratio is 0.5, it means that the risk of the event is reduced by half for individuals with a one-unit increase in that variable. Hazard ratios are used to determine the effect of a predictor variable on the risk of an event, and they provide a useful tool for comparing the risk of different groups.\n",
    "\n",
    "The terms Cox's Proportional Hazards Model and Cox Regression are used to describe the same statistical model, which is a semi-parametric regression model for analyzing time-to-event data. The key difference between the two terms is that Cox Regression refers to the linear regression version of the model, while Cox's Proportional Hazards Model refers to the model in its more general form, which includes non-linear as well as linear forms.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log-likelihood is a measure of the goodness of fit of a statistical model. In the context of the Cox Proportional Hazards Model, the log-likelihood is a measure of how well the model fits the data in terms of the time-to-event information and the event information.\n",
    "\n",
    "In general, the log-likelihood of a model is defined as the logarithm of the likelihood function, which is a function that describes the probability of observing the data given the parameters of the model. The likelihood function measures the compatibility of the observed data with the model, and the log-likelihood transforms this compatibility into a logarithmic scale, making it easier to work with and compare different models.\n",
    "\n",
    "In the case of the Cox Proportional Hazards Model, the log-likelihood measures the compatibility of the model with the data in terms of the hazard function, which is the instantaneous risk of an event occurring at a given time. A high log-likelihood indicates that the model fits the data well, and a low log-likelihood indicates that the model does not fit the data well.\n",
    "\n",
    "The log-likelihood is often used as a criterion for selecting the best model from a set of candidate models, or for estimating the parameters of a model in a maximum likelihood estimation procedure. When used in cross-validation, the log-likelihood can provide a measure of the performance of the model on new, unseen data.\n",
    "\n",
    "Fit a Cox's Proportion Hazard model with dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import CoxPHFitter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "# Specify the duration column and the event column\n",
    "duration_col = \"overall_survival_months_meta\"\n",
    "event_col = \"overall_survival_meta\"\n",
    "# subset only numeric columns\n",
    "#df = clinical.select_dtypes(include=['number']).copy()\n",
    "df = clinical[[duration_col, event_col]].copy()\n",
    "# recode the event column to numeric\n",
    "df[event_col] = clinical[event_col].map({'alive': 0, 'dead': 1})\n",
    "# remove rows with na values\n",
    "df = df.dropna()\n",
    "# Define the number of folds for cross-validation\n",
    "k = 5\n",
    "# Create the cross-validation object\n",
    "kf = StratifiedKFold(n_splits=k, shuffle=True)\n",
    "# Initialize a list to store the log-likelihoods from each fold\n",
    "log_likelihoods = []\n",
    "# Loop over the folds\n",
    "for train_index, val_index in kf.split(df, df[event_col]):\n",
    "    # Split the data into training and validation sets\n",
    "    df_train, df_val = df.iloc[train_index], df.iloc[val_index]\n",
    "    \n",
    "    # Fit the Cox Proportional Hazards Model on the training data\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(df_train, duration_col=duration_col, event_col=event_col)\n",
    "    \n",
    "    # Compute the log-likelihood of the model on the validation data\n",
    "    #log_likelihood = cph.score(df_val)\n",
    "    log_likelihood = cph.score(df_val, scoring_method='concordance_index')\n",
    "\n",
    "    # Store the log-likelihood\n",
    "    log_likelihoods.append(log_likelihood)\n",
    "\n",
    "# Compute the mean and standard deviation of the log-likelihoods\n",
    "mean_log_likelihood = np.mean(log_likelihoods)\n",
    "# Print the results\n",
    "print(\"Mean log-likelihood: {:.2f}\".format(mean_log_likelihood))\n",
    "\n",
    "# fit model with all data\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(df, duration_col=duration_col, event_col=event_col)\n",
    "# print the coefficients\n",
    "cph.print_summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the Cox's Proportion Hazard Model with all numeric variabls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import CoxPHFitter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "# Specify the duration column and the event column\n",
    "duration_col = \"overall_survival_months_meta\"\n",
    "event_col = \"overall_survival_meta\"\n",
    "# subset only numeric columns\n",
    "df = clinical.select_dtypes(include=['number']).copy()\n",
    "# recode the event column to numeric\n",
    "df[event_col] = clinical[event_col].map({'alive': 0, 'dead': 1})\n",
    "# remove rows with na values\n",
    "df = df.dropna()\n",
    "# Define the number of folds for cross-validation\n",
    "k = 5\n",
    "# Create the cross-validation object\n",
    "kf = StratifiedKFold(n_splits=k, shuffle=True)\n",
    "# Initialize a list to store the log-likelihoods from each fold\n",
    "log_likelihoods = []\n",
    "# Loop over the folds\n",
    "for train_index, val_index in kf.split(df, df[event_col]):\n",
    "    # Split the data into training and validation sets\n",
    "    df_train, df_val = df.iloc[train_index], df.iloc[val_index]\n",
    "    \n",
    "    # Fit the Cox Proportional Hazards Model on the training data\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(df_train, duration_col=duration_col, event_col=event_col)\n",
    "    \n",
    "    # Compute the log-likelihood of the model on the validation data\n",
    "    log_likelihood = cph.score(df_val, scoring_method='concordance_index')\n",
    "    \n",
    "    # Store the log-likelihood\n",
    "    log_likelihoods.append(log_likelihood)\n",
    "\n",
    "# Compute the mean and standard deviation of the log-likelihoods\n",
    "mean_log_likelihood = np.mean(log_likelihoods)\n",
    "std_log_likelihood = np.std(log_likelihoods)\n",
    "\n",
    "# Print the results\n",
    "print(\"Mean log-likelihood: {:.2f}\".format(mean_log_likelihood))\n",
    "print(\"Standard deviation of log-likelihood: {:.2f}\".format(std_log_likelihood))\n",
    "\n",
    "# fit model with all data\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(df, duration_col=duration_col, event_col=event_col)\n",
    "# print the coefficients\n",
    "cph.print_summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Dimension Data\n",
    "\n",
    "StatsModel package link [here](https://www.statsmodels.org/stable/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# we do not need to scale the data because all 20000 features are measured on the same scale.\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# transpose expression data\n",
    "exp_t = expression.to_numpy().transpose()\n",
    "\n",
    "# create a PCA model with 2 components\n",
    "pca = PCA(n_components=4)\n",
    "\n",
    "# fit the model to the data\n",
    "pca.fit(exp_t)\n",
    "\n",
    "# Access the components\n",
    "X_pca = pca.components_.transpose()\n",
    "# generate plot\n",
    "fig, ax = plt.subplots(2,2, figsize=(20, 10))\n",
    "# generate plot\n",
    "sns.scatterplot(\n",
    "    x=X_pca[ : , 0],\n",
    "    y=X_pca[ : , 1 ],\n",
    "    hue=clinical['overall_survival_meta'].fillna(value = \"NA\").to_list(),\n",
    "    ax=ax[0, 0]\n",
    "    )\n",
    "# generate plot\n",
    "sns.scatterplot(\n",
    "    x=X_pca[ : , 0],\n",
    "    y=X_pca[ : , 2 ],\n",
    "    hue=clinical['overall_survival_meta'].fillna(value = \"NA\").to_list(),\n",
    "    ax=ax[0, 1]\n",
    "    )\n",
    "# generate plot  \n",
    "sns.scatterplot(\n",
    "    x=X_pca[ : , 1],\n",
    "    y=X_pca[ : , 2 ],\n",
    "    hue=clinical['overall_survival_meta'].fillna(value = \"NA\").to_list(),\n",
    "    ax=ax[1, 0]\n",
    "    )\n",
    "# generate plot\n",
    "sns.scatterplot(\n",
    "    x=X_pca[ : , 2],\n",
    "    y=X_pca[ : , 0 ],\n",
    "    hue=clinical['overall_survival_meta'].fillna(value = \"NA\").to_list(),\n",
    "    ax=ax[1, 1]\n",
    "    )\n",
    "\n",
    "ax[0,0].set_title(\"PC1 vs PC2\")\n",
    "ax[0,1].set_title(\"PC1 vs PC2\")\n",
    "ax[1,0].set_title(\"PC2 vs PC3\")\n",
    "ax[1,1].set_title(\"PC3 vs PC1\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an heatmap visualizing all features and samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate heatmap of expression data\n",
    "sns.clustermap(exp_t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we identify a set of molecules with different distribution between event survival and not?\n",
    "\n",
    "For this task, multivariate regression modelling will be used. Multivariate regression is a statistical method that models the relationship between multiple independent variables and a dependent variable. It allows us to understand how changes in one or more independent variables influence the dependent variable and can be used to make predictions. This method assumes that there is a linear relationship between the variables and can be represented mathematically as a linear equation with multiple coefficients. The coefficients are estimated using data and the method of least squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# plot the distribution of the cause of death\n",
    "sns.boxplot(\n",
    "    x='age_at_diagnosis_meta',\n",
    "    y='death_from_cancer_meta', \n",
    "    data=clinical)\n",
    "\n",
    "# count the number of patients in each category\n",
    "clinical['death_from_cancer_meta'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove patients that died for other causes from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows in the category Died of Other Causes\n",
    "expr = expression[clinical['death_from_cancer_meta'] != 'Died of Other Causes'].copy()\n",
    "# copy clinical data\n",
    "meta_df = clinical[clinical['death_from_cancer_meta'] != 'Died of Other Causes'].copy()\n",
    "# create a new dataset of measurements and metadata\n",
    "df = pd.concat([expr, meta_df], axis=1)\n",
    "# print dimensions of the new dataset\n",
    "print(df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quantification of molecules is done with multivariate linear regression analysis. \n",
    "\n",
    "Multivariate linear regression analysis is a statistical method used to model the relationship between multiple independent variables (also known as predictors) and a single dependent variable (also known as response or outcome). The goal of this analysis is to find the best linear combination of independent variables that predicts the dependent variable, which is represented by an equation with a set of coefficients. The quality of the model is typically evaluated based on its ability to explain the variation in the dependent variable, and to make accurate predictions based on the independent variables.\n",
    "\n",
    "The aim is to determine the effect of death_from_cancer_meta on the quantification of each molecule using a linear model, where age and death_from_cancer_meta are the independent variables and the quantification of the molecule is the dependent variable. In bioinformatics, this process is called differential expression analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "df = df.dropna(subset=[\n",
    "    'death_from_cancer_meta', \n",
    "    'age_at_diagnosis_meta', \n",
    "    'brca1_expr'\n",
    "    ])\n",
    "\n",
    "X = pd.get_dummies(df[['death_from_cancer_meta', 'age_at_diagnosis_meta']])\n",
    "y = df['brca1_expr']\n",
    "# fit the model to ols\n",
    "model = sm.OLS(\n",
    "    y, \n",
    "    sm.add_constant(X)\n",
    "    ).fit()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The False Discovery Rate (FDR) is a measure of the proportion of false positives among all the significant results (i.e., rejected null hypotheses) in a multiple hypothesis test. In other words, it is the expected proportion of false positive results among the significant results. FDR is used in statistical analysis to control the number of false positives and maintain the overall error rate at a desired level, usually set at a small value such as 0.05 or 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = model.pvalues[1:]\n",
    "_, corrected_pvals, _, _ = multipletests(pvals, method='fdr_bh')\n",
    "\n",
    "corrected_pvals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automated the process to estimate fdr for all molecules in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "X = pd.get_dummies(df[['death_from_cancer_meta', 'age_at_diagnosis_meta']])\n",
    "\n",
    "fdr_df = list()\n",
    "\n",
    "for molecule in expression.columns:\n",
    "    y = df[molecule]\n",
    "    # fit the model to ols\n",
    "    model = sm.OLS(\n",
    "        y, \n",
    "        sm.add_constant(X)\n",
    "        ).fit()\n",
    "    # create sumamry table\n",
    "    summary = model.summary2().tables[1]\n",
    "    # retrieve p-values\n",
    "    pvals = model.pvalues[1:]\n",
    "    # add gene name\n",
    "    summary['gene'] = molecule\n",
    "    # correct p-values\n",
    "    _, corrected_pvals, _, _ = multipletests(pvals, method='fdr_bh')\n",
    "    # add corrected p-values to the dataframe\n",
    "    summary = summary.join(pd.DataFrame(corrected_pvals, index=X.columns, columns=['pval_corrected']))\n",
    "    # append to fdr_df\n",
    "    fdr_df.append(summary)\n",
    "summary = pd.concat(fdr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort summary by pval_corrected\n",
    "summary = summary.sort_values('pval_corrected', ascending=True)\n",
    "living_coeff = summary.loc['death_from_cancer_meta_Living']\n",
    "fdr_genes = living_coeff[living_coeff['pval_corrected'] < 0.01]['gene']\n",
    "print( f'total number of molecules with influence on survival {fdr_genes.shape}' )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show graphic for the first 10 top genes. This is a visual inspection to understand how strong is the change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subplot figure with 5 rows and 5 columns\n",
    "fig, ax = plt.subplots(2, 5, figsize=(20, 20))\n",
    "\n",
    "# Iterate over the genes\n",
    "for n in range(10):\n",
    "    target = fdr_genes[n]\n",
    "    # Generate boxplot of ready_to_print genes by death_from_cancer_meta\n",
    "    row = n // 5\n",
    "    col = n % 5\n",
    "    sns.boxplot(\n",
    "        x='death_from_cancer_meta',\n",
    "        y=target,\n",
    "        data=df,\n",
    "        ax=ax[row, col]\n",
    "    ).set_title(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create heatmpa of all genes\n",
    "sns.clustermap(exp_t, cmap='viridis', z_score='none', figsize=(4,4))\n",
    "# create heatmap of top 10 genes\n",
    "sns.clustermap(df[fdr_genes[:10]], cmap='viridis', z_score='none', figsize=(4,4))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Responder (survival) with machine learning\n",
    "\n",
    "Here we use PyCaret to try several models and find the best performing. It is a prime on PyCaret, and you can find a nice tutorial [here](https://michael-fuchs-python.netlify.app/2022/01/01/automl-using-pycaret-classification/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataset for the training\n",
    "model_df = df.drop([\"overall_survival_meta\", \"overall_survival_months_meta\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the PyCaret setup function\n",
    "from pycaret.classification import *\n",
    "clf = setup(\n",
    "    data = model_df, \n",
    "    target = 'death_from_cancer_meta', \n",
    "    session_id=123,\n",
    "    normalize = True, \n",
    "    transformation = True, \n",
    "    ignore_low_variance = True,\n",
    "    remove_multicollinearity = True, \n",
    "    multicollinearity_threshold = 0.95\n",
    "    ) \n",
    "\n",
    "available_models = models()\n",
    "available_models\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = compare_models(sort = 'AUC', include=['dt', 'rf', 'xgboost'])\n",
    "print(best_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_best_clf = evaluate_model(best_clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = finalize_model(best_clf)\n",
    "save_model(final_model, '../models/my_model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model interpretation with SHAP values\n",
    "\n",
    "Please see documentation [here](https://shap.readthedocs.io/en/latest/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7346cb4d4c11a18938dd757e912f2dfe8a4a5ef599c0d403d5973a0a2997bf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
